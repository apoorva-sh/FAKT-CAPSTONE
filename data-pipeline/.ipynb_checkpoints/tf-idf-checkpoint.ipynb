{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.io.json import json_normalize\n",
    "import spacy as sp\n",
    "import en_core_web_sm\n",
    "import string\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdata_json = pd.read_json('relevant_news_10K.json')\n",
    "irdata_json = pd.read_json('irrelevant_news_10K.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rdata_json['relevance']=1\n",
    "irdata_json['relevance']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>headline</th>\n",
       "      <th>source</th>\n",
       "      <th>summary</th>\n",
       "      <th>uid</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The lowly milkshake has turned into an unlikel...</td>\n",
       "      <td>Milkshakes become weapon of choice in UK Europ...</td>\n",
       "      <td>Agence France Presse</td>\n",
       "      <td>Former UK Independence Party leader Nigel Fara...</td>\n",
       "      <td>a437ff48-104a-54bb-bff7-c7a736158524</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANZ has moved to the front of the race that’s ...</td>\n",
       "      <td>ANZ's first assault in the looming job armageddon</td>\n",
       "      <td>News Ltd.</td>\n",
       "      <td>ANZ has moved to the front of the race that’ s...</td>\n",
       "      <td>366c92af-8143-5ffa-8702-4f26bd22c8b6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jul. 10--Carnival Cruise Line stateroom attend...</td>\n",
       "      <td>Carnival Cruise Line to collect your used soap...</td>\n",
       "      <td>Tribune Content Agency</td>\n",
       "      <td>Jul. 10-- Carnival Cruise Line stateroom atten...</td>\n",
       "      <td>863096d4-48f0-5a7c-bee6-384a76d575ee</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHENNAI: R Rohit (5/43) and P Saravanan (5/46)...</td>\n",
       "      <td>Standard CC bags fourth title in a row [New In...</td>\n",
       "      <td>SyndiGate Media Inc.</td>\n",
       "      <td>CHENNAI: R Rohit and P Saravanan took five wic...</td>\n",
       "      <td>3e4d6490-4224-595e-be26-4cb249209b8f</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donald Trump’s nominee to lead the US Fish and...</td>\n",
       "      <td>Revealed: Trump's Wildlife Service pick has ti...</td>\n",
       "      <td>Guardian</td>\n",
       "      <td>New revelations show she also has ties to the ...</td>\n",
       "      <td>9f3e248d-b040-5058-bdc9-61c4de59f02a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  The lowly milkshake has turned into an unlikel...   \n",
       "1  ANZ has moved to the front of the race that’s ...   \n",
       "2  Jul. 10--Carnival Cruise Line stateroom attend...   \n",
       "3  CHENNAI: R Rohit (5/43) and P Saravanan (5/46)...   \n",
       "4  Donald Trump’s nominee to lead the US Fish and...   \n",
       "\n",
       "                                            headline                  source  \\\n",
       "0  Milkshakes become weapon of choice in UK Europ...    Agence France Presse   \n",
       "1  ANZ's first assault in the looming job armageddon               News Ltd.   \n",
       "2  Carnival Cruise Line to collect your used soap...  Tribune Content Agency   \n",
       "3  Standard CC bags fourth title in a row [New In...    SyndiGate Media Inc.   \n",
       "4  Revealed: Trump's Wildlife Service pick has ti...                Guardian   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Former UK Independence Party leader Nigel Fara...   \n",
       "1  ANZ has moved to the front of the race that’ s...   \n",
       "2  Jul. 10-- Carnival Cruise Line stateroom atten...   \n",
       "3  CHENNAI: R Rohit and P Saravanan took five wic...   \n",
       "4  New revelations show she also has ties to the ...   \n",
       "\n",
       "                                    uid  relevance  \n",
       "0  a437ff48-104a-54bb-bff7-c7a736158524          1  \n",
       "1  366c92af-8143-5ffa-8702-4f26bd22c8b6          1  \n",
       "2  863096d4-48f0-5a7c-bee6-384a76d575ee          1  \n",
       "3  3e4d6490-4224-595e-be26-4cb249209b8f          1  \n",
       "4  9f3e248d-b040-5058-bdc9-61c4de59f02a          1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = rdata_json.append(irdata_json, ignore_index=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create our list of punctuation marks\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# Create our list of stopwords\n",
    "nlp = en_core_web_sm.load()\n",
    "stop_words = sp.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "parser = English()\n",
    "\n",
    "# Creating our tokenizer function\n",
    "def spacy_tokenizer(sentence):\n",
    "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
    "    mytokens = parser(sentence)\n",
    "\n",
    "    # Lemmatizing each token and converting each token into lowercase\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "\n",
    "    # Removing stop words\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "\n",
    "    # return preprocessed list of tokens\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Custom transformer using spaCy\n",
    "class predictors(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        # Cleaning Text\n",
    "        return [clean_text(text) for text in X]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "# Basic function to clean the text\n",
    "def clean_text(text):\n",
    "    # Removing spaces and converting text into lowercase\n",
    "    return text.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vector = TfidfVectorizer(tokenizer = spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bow_vector = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = data['content'] # the features we want to analyze\n",
    "ylabels = data['relevance'] # the labels, or answers, we want to test against\n",
    "\n",
    "# X_train and y_train are the entire dataset (for now)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('cleaner', <__main__.predictors object at 0x11d640eb8>), ('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngr...penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression Classifier\n",
    "# Note: classifier is a placeholder for now\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "# Create pipeline using Bag of Words\n",
    "pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', tfidf_vector),\n",
    "                 ('classifier', classifier)])\n",
    "\n",
    "# model generation\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predicting with a test dataset\n",
    "# Note: this will fail if testing data size is 0\n",
    "predicted = pipe.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Logistic Regression Precision:\",metrics.precision_score(y_test, predicted))\n",
    "print(\"Logistic Regression Recall:\",metrics.recall_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# warning: this takes up a lot of space, but you can use the vectors within the notebook if you don't need to save.\n",
    "cleaned_X_train = pipe.named_steps[\"cleaner\"].transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleaned_X_train_tokens = [spacy_tokenizer(cleaned_X_train[i]) for i in range(len(cleaned_X_train))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('cleaned_X_train', cleaned_X_test)\n",
    "np.save('cleaned_X_train_tokens', cleaned_X_train_tokens)\n",
    "np.save('tfidf_vector', pipe.named_steps[\"vectorizer\"].transform(X_train))\n",
    "np.save('bow_vector', bow_vector.fit_transform(cleaned_X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
