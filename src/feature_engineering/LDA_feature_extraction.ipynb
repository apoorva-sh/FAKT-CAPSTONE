{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(relevant_path,irrelevant_path):\n",
    "    data_relevant = pd.read_json(relevant_path);\n",
    "    data_irrelevant = pd.read_json(irrelevant_path)\n",
    "    data_lda_train = pd.concat([data_relevant,data_irrelevant],axis=0)[['content','label']]\n",
    "    data_text = pd.concat([data_relevant,data_irrelevant],axis=0)[['content','label']]\n",
    "    data_text['index'] = data_text.index\n",
    "    return data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = load_data(\"../../data/clean/relevant_news.json\",\"../../data/clean/irrelevant_news.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/tharun/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pre-processing\n",
    "We convert the content to list of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    \"\"\"\n",
    "    Function to tokenize the text\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        result.append(token)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = documents['content'].map(preprocess)\n",
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create Test-Train Split for LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create test train split\n",
    "def test_train_split(dataframe,size):\n",
    "    label = [[0]]*10000\n",
    "    label.extend([[1]]*10000)\n",
    "    return train_test_split(processed_docs, label, test_size=0.2, random_state=42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = test_train_split(processed_docs,10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Bag of words (BoW)\n",
    "Generate bag of words feature set for LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample terms in dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 account\n",
      "1 add\n",
      "2 adviser\n",
      "3 alias\n",
      "4 angry\n",
      "5 asian\n",
      "6 association\n",
      "7 banana\n",
      "8 bellwether\n",
      "9 benjamin\n",
      "10 black\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter extremes from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate train and test corpus for BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in X_train]\n",
    "bow_test_corpus = [dictionary.doc2bow(doc) for doc in X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample BoW document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 18 (\"camp\") appears 2 time.\n",
      "Word 27 (\"city\") appears 2 time.\n",
      "Word 106 (\"press\") appears 2 time.\n",
      "Word 113 (\"request\") appears 1 time.\n",
      "Word 218 (\"days\") appears 1 time.\n",
      "Word 226 (\"drive\") appears 3 time.\n",
      "Word 257 (\"game\") appears 2 time.\n",
      "Word 349 (\"start\") appears 1 time.\n",
      "Word 462 (\"circle\") appears 1 time.\n",
      "Word 601 (\"field\") appears 2 time.\n"
     ]
    }
   ],
   "source": [
    "bow_doc_4310 = bow_corpus[0]\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], \n",
    "                                                     dictionary[bow_doc_4310[i][0]], \n",
    "                                                     bow_doc_4310[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. TF-IDF\n",
    "Generate TF-IDF scores from bow_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "corpus_tfidf = tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. LDA model using bag of words, 5 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=5, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.006*\"pm\" + 0.006*\"people\" + 0.004*\"police\" + 0.004*\"nt\" + 0.003*\"st\" + 0.003*\"city\" + 0.003*\"tell\" + 0.003*\"family\" + 0.003*\"day\" + 0.002*\"house\"\n",
      "Topic: 1 \n",
      "Words: 0.008*\"game\" + 0.006*\"play\" + 0.006*\"team\" + 0.006*\"nt\" + 0.005*\"season\" + 0.003*\"company\" + 0.003*\"start\" + 0.003*\"win\" + 0.002*\"coach\" + 0.002*\"market\"\n",
      "Topic: 2 \n",
      "Words: 0.009*\"company\" + 0.005*\"service\" + 0.004*\"report\" + 0.003*\"market\" + 0.003*\"project\" + 0.003*\"share\" + 0.003*\"people\" + 0.003*\"bank\" + 0.003*\"city\" + 0.003*\"plan\"\n",
      "Topic: 3 \n",
      "Words: 0.011*\"quarter\" + 0.010*\"company\" + 0.007*\"share\" + 0.006*\"business\" + 0.006*\"market\" + 0.005*\"net\" + 0.005*\"continue\" + 0.005*\"statements\" + 0.005*\"growth\" + 0.004*\"increase\"\n",
      "Topic: 4 \n",
      "Words: 0.012*\"market\" + 0.005*\"trump\" + 0.005*\"president\" + 0.005*\"table\" + 0.004*\"government\" + 0.004*\"people\" + 0.004*\"report\" + 0.003*\"minister\" + 0.003*\"party\" + 0.003*\"police\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Model using bag of words 10 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.009*\"market\" + 0.007*\"business\" + 0.007*\"service\" + 0.007*\"company\" + 0.006*\"growth\" + 0.005*\"quarter\" + 0.005*\"technology\" + 0.004*\"global\" + 0.004*\"continue\" + 0.004*\"data\"\n",
      "Topic: 1 \n",
      "Words: 0.016*\"quarter\" + 0.010*\"net\" + 0.009*\"share\" + 0.008*\"company\" + 0.007*\"cash\" + 0.007*\"income\" + 0.006*\"operate\" + 0.006*\"continue\" + 0.006*\"increase\" + 0.006*\"financial\"\n",
      "Topic: 2 \n",
      "Words: 0.017*\"company\" + 0.008*\"market\" + 0.007*\"share\" + 0.006*\"statements\" + 0.005*\"forwardlooking\" + 0.005*\"quarter\" + 0.004*\"price\" + 0.004*\"business\" + 0.004*\"offer\" + 0.004*\"release\"\n",
      "Topic: 3 \n",
      "Words: 0.028*\"market\" + 0.017*\"table\" + 0.007*\"share\" + 0.007*\"analysis\" + 0.006*\"type\" + 0.005*\"company\" + 0.005*\"historic\" + 0.005*\"city\" + 0.004*\"sales\" + 0.004*\"pm\"\n",
      "Topic: 4 \n",
      "Words: 0.007*\"trump\" + 0.006*\"people\" + 0.006*\"nt\" + 0.005*\"president\" + 0.003*\"tell\" + 0.003*\"house\" + 0.002*\"campaign\" + 0.002*\"court\" + 0.002*\"party\" + 0.002*\"time\"\n",
      "Topic: 5 \n",
      "Words: 0.004*\"company\" + 0.004*\"people\" + 0.004*\"health\" + 0.004*\"government\" + 0.004*\"report\" + 0.004*\"court\" + 0.004*\"patients\" + 0.003*\"drug\" + 0.003*\"nt\" + 0.003*\"public\"\n",
      "Topic: 6 \n",
      "Words: 0.009*\"game\" + 0.008*\"pm\" + 0.006*\"nt\" + 0.006*\"play\" + 0.005*\"season\" + 0.004*\"team\" + 0.004*\"st\" + 0.004*\"start\" + 0.003*\"city\" + 0.003*\"win\"\n",
      "Topic: 7 \n",
      "Words: 0.008*\"company\" + 0.006*\"market\" + 0.004*\"water\" + 0.004*\"people\" + 0.004*\"power\" + 0.004*\"party\" + 0.003*\"vote\" + 0.003*\"plan\" + 0.003*\"government\" + 0.003*\"energy\"\n",
      "Topic: 8 \n",
      "Words: 0.009*\"police\" + 0.006*\"team\" + 0.004*\"county\" + 0.004*\"city\" + 0.003*\"play\" + 0.003*\"news\" + 0.003*\"people\" + 0.003*\"officer\" + 0.003*\"agency\" + 0.003*\"south\"\n",
      "Topic: 9 \n",
      "Words: 0.007*\"people\" + 0.005*\"report\" + 0.005*\"company\" + 0.004*\"share\" + 0.004*\"president\" + 0.004*\"video\" + 0.004*\"nt\" + 0.003*\"issue\" + 0.003*\"house\" + 0.003*\"trump\"\n"
     ]
    }
   ],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.save(\"../../models/lda_bow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. LDA model using TF-IDF, 5 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=5, id2word=dictionary, passes=4, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.004*\"company\" + 0.004*\"market\" + 0.003*\"quarter\" + 0.003*\"share\" + 0.002*\"statements\" + 0.002*\"forwardlooking\" + 0.002*\"business\" + 0.002*\"growth\" + 0.002*\"financial\" + 0.002*\"products\"\n",
      "\n",
      "\n",
      " 0.003*\"game\" + 0.003*\"play\" + 0.002*\"season\" + 0.002*\"zacks\" + 0.002*\"pm\" + 0.002*\"nt\" + 0.002*\"team\" + 0.002*\"film\" + 0.002*\"coach\" + 0.002*\"win\"\n",
      "\n",
      "\n",
      " 0.003*\"trump\" + 0.002*\"government\" + 0.002*\"president\" + 0.002*\"minister\" + 0.002*\"people\" + 0.001*\"house\" + 0.001*\"party\" + 0.001*\"city\" + 0.001*\"china\" + 0.001*\"percent\"\n",
      "\n",
      "\n",
      " 0.009*\"police\" + 0.003*\"arrest\" + 0.003*\"russian\" + 0.003*\"officer\" + 0.002*\"court\" + 0.002*\"india\" + 0.002*\"suspect\" + 0.002*\"charge\" + 0.002*\"moscow\" + 0.002*\"delhi\"\n",
      "\n",
      "\n",
      " 0.005*\"icra\" + 0.003*\"bond\" + 0.003*\"mln\" + 0.002*\"certificate\" + 0.002*\"bjp\" + 0.002*\"issue\" + 0.002*\"deposit\" + 0.002*\"dec\" + 0.002*\"interbank\" + 0.002*\"bln\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('',topic)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA model suing TF-IDF 10 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.003*\"police\" + 0.002*\"pm\" + 0.001*\"school\" + 0.001*\"city\" + 0.001*\"flight\" + 0.001*\"boeing\" + 0.001*\"county\" + 0.001*\"nt\" + 0.001*\"company\" + 0.001*\"friday\"\n",
      "\n",
      "\n",
      "Topic: 1 Word: 0.002*\"trump\" + 0.002*\"game\" + 0.002*\"percent\" + 0.002*\"china\" + 0.001*\"tariff\" + 0.001*\"play\" + 0.001*\"trade\" + 0.001*\"india\" + 0.001*\"nt\" + 0.001*\"season\"\n",
      "\n",
      "\n",
      "Topic: 2 Word: 0.003*\"trump\" + 0.002*\"nt\" + 0.001*\"president\" + 0.001*\"quarter\" + 0.001*\"house\" + 0.001*\"people\" + 0.001*\"company\" + 0.001*\"police\" + 0.001*\"bank\" + 0.001*\"report\"\n",
      "\n",
      "\n",
      "Topic: 3 Word: 0.004*\"company\" + 0.003*\"statements\" + 0.003*\"market\" + 0.003*\"forwardlooking\" + 0.003*\"quarter\" + 0.002*\"share\" + 0.002*\"financial\" + 0.002*\"business\" + 0.002*\"products\" + 0.002*\"service\"\n",
      "\n",
      "\n",
      "Topic: 4 Word: 0.002*\"minister\" + 0.001*\"court\" + 0.001*\"police\" + 0.001*\"government\" + 0.001*\"people\" + 0.001*\"trump\" + 0.001*\"nt\" + 0.001*\"game\" + 0.001*\"pm\" + 0.001*\"president\"\n",
      "\n",
      "\n",
      "Topic: 5 Word: 0.002*\"game\" + 0.002*\"nt\" + 0.002*\"season\" + 0.002*\"play\" + 0.001*\"team\" + 0.001*\"school\" + 0.001*\"coach\" + 0.001*\"people\" + 0.001*\"company\" + 0.001*\"start\"\n",
      "\n",
      "\n",
      "Topic: 6 Word: 0.002*\"game\" + 0.002*\"hartford\" + 0.001*\"police\" + 0.001*\"team\" + 0.001*\"season\" + 0.001*\"company\" + 0.001*\"play\" + 0.001*\"nt\" + 0.001*\"pm\" + 0.001*\"people\"\n",
      "\n",
      "\n",
      "Topic: 7 Word: 0.002*\"trump\" + 0.002*\"police\" + 0.001*\"company\" + 0.001*\"president\" + 0.001*\"city\" + 0.001*\"house\" + 0.001*\"court\" + 0.001*\"people\" + 0.001*\"government\" + 0.001*\"nt\"\n",
      "\n",
      "\n",
      "Topic: 8 Word: 0.004*\"zacks\" + 0.003*\"share\" + 0.003*\"cents\" + 0.002*\"company\" + 0.002*\"report\" + 0.002*\"stock\" + 0.002*\"investment\" + 0.002*\"police\" + 0.002*\"revenue\" + 0.001*\"market\"\n",
      "\n",
      "\n",
      "Topic: 9 Word: 0.001*\"company\" + 0.001*\"bond\" + 0.001*\"cent\" + 0.001*\"market\" + 0.001*\"issue\" + 0.001*\"news\" + 0.001*\"police\" + 0.001*\"dec\" + 0.001*\"trade\" + 0.001*\"game\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=4, workers=10)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_tfidf.save(\"../../models/lda_tfidf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Results for sample document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.49756285548210144\t \n",
      "Topic: 0.007*\"trump\" + 0.006*\"people\" + 0.006*\"nt\" + 0.005*\"president\" + 0.003*\"tell\"\n",
      "\n",
      "Score: 0.4707499146461487\t \n",
      "Topic: 0.009*\"police\" + 0.006*\"team\" + 0.004*\"county\" + 0.004*\"city\" + 0.003*\"play\"\n",
      "\n",
      "Score: 0.029671287164092064\t \n",
      "Topic: 0.007*\"people\" + 0.005*\"report\" + 0.005*\"company\" + 0.004*\"share\" + 0.004*\"president\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Generate LDA features for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in range(16000):\n",
    "    row=np.zeros(10)\n",
    "    for index, score in lda_model[bow_corpus[doc]]:\n",
    "        row[index] = score\n",
    "    features_train.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in range(10):\n",
    "    row=np.zeros(10)\n",
    "    for index, score in lda_model[bow_test_corpus[doc]]:\n",
    "        row[index] = score\n",
    "    features_test.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Dump features onto file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(Y_train).reshape(-1)\n",
    "features_train = pd.concat([pd.DataFrame(features_train),pd.Series(y).rename('label')],axis=1)\n",
    "features_train.head(5)\n",
    "features_train.head(5).to_csv(\"../../data/feature/lda_features_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(Y_test).reshape(-1)\n",
    "features_test = pd.concat([pd.DataFrame(features_test),pd.Series(y).rename('label')],axis=1)\n",
    "features_test.head(5).to_csv(\"../../data/feature/lda_features_test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
