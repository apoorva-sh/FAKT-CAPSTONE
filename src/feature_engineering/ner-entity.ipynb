{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import spacy as sp\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>headline</th>\n",
       "      <th>source</th>\n",
       "      <th>summary</th>\n",
       "      <th>uid</th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lowly milkshake weapon choice britons determin...</td>\n",
       "      <td>Milkshakes become weapon of choice in UK Europ...</td>\n",
       "      <td>Agence France Presse</td>\n",
       "      <td>Former UK Independence Party leader Nigel Fara...</td>\n",
       "      <td>a437ff48-104a-54bb-bff7-c7a736158524</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anz race set bring biggest white collar job lo...</td>\n",
       "      <td>ANZ's first assault in the looming job armageddon</td>\n",
       "      <td>News Ltd.</td>\n",
       "      <td>ANZ has moved to the front of the race that’ s...</td>\n",
       "      <td>366c92af-8143-5ffa-8702-4f26bd22c8b6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jul 10 carnival cruise stateroom attendants ex...</td>\n",
       "      <td>Carnival Cruise Line to collect your used soap...</td>\n",
       "      <td>Tribune Content Agency</td>\n",
       "      <td>Jul. 10-- Carnival Cruise Line stateroom atten...</td>\n",
       "      <td>863096d4-48f0-5a7c-bee6-384a76d575ee</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chennai rohit 543 saravanan 546 wickets standa...</td>\n",
       "      <td>Standard CC bags fourth title in a row [New In...</td>\n",
       "      <td>SyndiGate Media Inc.</td>\n",
       "      <td>CHENNAI: R Rohit and P Saravanan took five wic...</td>\n",
       "      <td>3e4d6490-4224-595e-be26-4cb249209b8f</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>donald trump nominee lead fish wildlife servic...</td>\n",
       "      <td>Revealed: Trump's Wildlife Service pick has ti...</td>\n",
       "      <td>Guardian</td>\n",
       "      <td>New revelations show she also has ties to the ...</td>\n",
       "      <td>9f3e248d-b040-5058-bdc9-61c4de59f02a</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  lowly milkshake weapon choice britons determin...   \n",
       "1  anz race set bring biggest white collar job lo...   \n",
       "2  jul 10 carnival cruise stateroom attendants ex...   \n",
       "3  chennai rohit 543 saravanan 546 wickets standa...   \n",
       "4  donald trump nominee lead fish wildlife servic...   \n",
       "\n",
       "                                            headline                  source  \\\n",
       "0  Milkshakes become weapon of choice in UK Europ...    Agence France Presse   \n",
       "1  ANZ's first assault in the looming job armageddon               News Ltd.   \n",
       "2  Carnival Cruise Line to collect your used soap...  Tribune Content Agency   \n",
       "3  Standard CC bags fourth title in a row [New In...    SyndiGate Media Inc.   \n",
       "4  Revealed: Trump's Wildlife Service pick has ti...                Guardian   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Former UK Independence Party leader Nigel Fara...   \n",
       "1  ANZ has moved to the front of the race that’ s...   \n",
       "2  Jul. 10-- Carnival Cruise Line stateroom atten...   \n",
       "3  CHENNAI: R Rohit and P Saravanan took five wic...   \n",
       "4  New revelations show she also has ties to the ...   \n",
       "\n",
       "                                    uid  index  label  relevance  \n",
       "0  a437ff48-104a-54bb-bff7-c7a736158524      0      1          1  \n",
       "1  366c92af-8143-5ffa-8702-4f26bd22c8b6      1      1          1  \n",
       "2  863096d4-48f0-5a7c-bee6-384a76d575ee      2      1          1  \n",
       "3  3e4d6490-4224-595e-be26-4cb249209b8f      3      1          1  \n",
       "4  9f3e248d-b040-5058-bdc9-61c4de59f02a      4      1          1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdata = pd.read_json('../../data/clean/relevantNewsNLTK4.json')\n",
    "irdata = pd.read_json('../../data/clean/irrelevantNewsNLTK4.json')\n",
    "rdata['relevance']=1\n",
    "irdata['relevance']=0\n",
    "data = rdata.append(irdata, ignore_index=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['relevance'], axis=1) # the features we want to analyze\n",
    "y = data['relevance'] # the labels, or answers, we want to test against\n",
    "\n",
    "# X_train and y_train are the entire dataset (for now)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = sp.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hash(text):\n",
    "    hash_df = {}\n",
    "    doc = nlp(text)\n",
    "    for entity in doc.ents:\n",
    "        if entity.label_ not in hash_df:\n",
    "            hash_df[entity.label_] = 0\n",
    "        hash_df[entity.label_] = hash_df[entity.label_] + 1\n",
    "    return hash_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ner_vector(data, feature):\n",
    "    '''\n",
    "    Input: dataframe of news article data, column to perform function\n",
    "    Output: dataframe of articles with entities as columns and counts of each entity as values\n",
    "    Notes: column entity definitions: https://spacy.io/api/annotation#named-entities\n",
    "    '''\n",
    "    columns = ['uid', 'PERSON', 'NORP', 'FAC', 'ORG', 'GPE', 'LOC', 'PRODUCT', 'EVENT', 'WORK_OF_ART', \\\n",
    "               'LAW', 'LANGUAGE', 'DATE', 'TIME', 'PERCENT', 'MONEY', 'QUANTITY', 'ORGINAL', 'CARDINAL']\n",
    "    df = pd.DataFrame(index=data.index, columns=columns)\n",
    "    df['uid'] = data['uid']\n",
    "    i = 0\n",
    "    for index, row in data.iterrows():\n",
    "        if (i % 1000 == 0):\n",
    "            print('progress: ', i)\n",
    "        text = row[feature]\n",
    "        hash_df = generate_hash(text)\n",
    "        itercol = iter(columns)\n",
    "        next(itercol)\n",
    "        for col in itercol:\n",
    "            if col in hash_df:\n",
    "                df.at[index, col] = hash_df[col]\n",
    "            else:\n",
    "                df.at[index, col] = 0\n",
    "        i += 1\n",
    "    # diagnostics\n",
    "    # print(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress:  0.0\n",
      "progress:  0.1\n",
      "progress:  0.2\n",
      "progress:  0.3\n",
      "progress:  0.4\n",
      "progress:  0.5\n",
      "progress:  0.6\n",
      "progress:  0.7\n",
      "progress:  0.8\n",
      "progress:  0.9\n",
      "progress:  1.0\n",
      "progress:  1.1\n",
      "progress:  1.2\n",
      "progress:  1.3\n",
      "progress:  1.4\n",
      "progress:  1.5\n"
     ]
    }
   ],
   "source": [
    "# Generate dataframe with rows of articles, and columns of entities; cells are counts of each entity in the article content\n",
    "# Test Case: rdata_ner_df = generate_ner_vector(rdata.loc[[0]], \"content\")\n",
    "\n",
    "train_ner = generate_ner_vector(X_train, \"content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ner['label'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress:  0.0\n",
      "progress:  0.1\n",
      "progress:  0.2\n",
      "progress:  0.3\n"
     ]
    }
   ],
   "source": [
    "test_ner = generate_ner_vector(X_test, \"content\")\n",
    "test_ner['label'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ner.to_csv('../../data/feature/train_ner.csv')\n",
    "test_ner.to_csv('../../data/feature/test_ner.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_extractor(data, entity, column_name):\n",
    "    '''\n",
    "    Input: dataframe, entity from spaCy, column name from dataset\n",
    "    Output: list of words that are matched to the given entity\n",
    "    '''\n",
    "    words_names = []\n",
    "    for idx, line in data.iterrows():\n",
    "        if (idx % 2000 == 0):\n",
    "            print(\"index: {}\".format(idx))\n",
    "        doc = nlp(line[column_name])\n",
    "        names = [ent.text for ent in doc.ents if ent.label_ == entity]\n",
    "        words_names.append(names)\n",
    "    return words_names\n",
    "\n",
    "def top_x_common_entity(words_names, x):\n",
    "    '''\n",
    "    Input: list of words that are matched to the given entity, integer to specify top x number of words\n",
    "    '''\n",
    "    names = [line for line in words_names for line in set(line)]\n",
    "    names_count = Counter(names).most_common(x)\n",
    "    print(pd.DataFrame(names_count))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
